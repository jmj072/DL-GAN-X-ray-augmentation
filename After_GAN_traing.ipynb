{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"After_GAN_traing_epoch_1000.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPKh4klTgdmpLu7nuch4jAQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["**코로나19 환자의 Fake X-ray data를 사용하여 CNN 학습**\n","\n","- 정상군 :1266명\n","- 코로나 19환자 : 1460명"],"metadata":{"id":"SuVTlxUo1yGQ"}},{"cell_type":"markdown","source":["# 라이브러리 및 패키지"],"metadata":{"id":"bQ_WlWNN0sYJ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"5xQdI_NjgP16"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import glob\n","import os\n","import time\n","import PIL\n","import tensorflow as tf\n","\n","#모델 생성\n","from tensorflow.keras import Sequential\n","from tensorflow.keras import layers\n","from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n","from tensorflow.keras.layers import Dense, Flatten\n","from tensorflow.keras.models import Sequential\n","from keras.preprocessing.image import array_to_img, img_to_array, load_img, image_dataset_from_directory\n","from keras.callbacks import ModelCheckpoint, EarlyStopping\n","\n","#모델저장\n","import joblib"]},{"cell_type":"markdown","source":["# 데이터셋 형성 및 이미지 전처리"],"metadata":{"id":"nZFQYdgp0uyK"}},{"cell_type":"code","source":["#구글 드라이브 mount\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"irqfgtD6gUf5","executionInfo":{"status":"ok","timestamp":1641915117309,"user_tz":-540,"elapsed":17138,"user":{"displayName":"지민진","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02076462248414665689"}},"outputId":"f38676b1-454e-4cf5-de81-f7da3cd6a916"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# 이미지 관련 변수, 모델학습 변수\n","\n","batch_size = 128\n","img_height = 128\n","img_width = 128\n","seed = 42\n","epoch = 500"],"metadata":{"id":"bmHPOE3NgVx_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Dataset 형성\n","\n","train_path=\"/content/drive/MyDrive/CodeStates/Section4/project/After_GAN_1000/train\"\n","test_path=\"/content/drive/MyDrive/CodeStates/Section4/project/After_GAN_1000/test\"\n","\n","train_ds = image_dataset_from_directory(\n","  train_path,\n","  validation_split=0.2,\n","  subset=\"training\",\n","  seed=seed,\n","  image_size=(img_height, img_width),\n","  batch_size=batch_size)\n","\n","val_ds = image_dataset_from_directory(\n","  train_path,\n","  validation_split=0.2,\n","  subset=\"validation\",\n","  seed=seed,\n","  image_size=(img_height, img_width),\n","  batch_size=batch_size)\n","\n","test_ds =  image_dataset_from_directory(\n","  test_path,\n","  seed=seed,\n","  image_size=(img_height, img_width),\n","  batch_size=batch_size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mZf45ZSpgZGf","executionInfo":{"status":"ok","timestamp":1641915130523,"user_tz":-540,"elapsed":13217,"user":{"displayName":"지민진","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02076462248414665689"}},"outputId":"bbecd1d2-d877-4e87-e9c1-c1764cce869a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 2437 files belonging to 2 classes.\n","Using 1950 files for training.\n","Found 2437 files belonging to 2 classes.\n","Using 487 files for validation.\n","Found 433 files belonging to 2 classes.\n"]}]},{"cell_type":"code","source":["# Class 확인\n","class_names = train_ds.class_names\n","print(class_names)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TtE8avWagdXW","executionInfo":{"status":"ok","timestamp":1641915130524,"user_tz":-540,"elapsed":12,"user":{"displayName":"지민진","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02076462248414665689"}},"outputId":"03b8f4db-9dda-4ff8-da29-5cd2312c5655"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['COVID19', 'NORMAL']\n"]}]},{"cell_type":"code","source":["#Train set에서 class 수 확인\n","num_images_train_normal = len(os.listdir(os.path.join(train_path,'NORMAL/')))\n","num_images_train_covid19 = len(os.listdir(os.path.join(train_path,'COVID19/')))\n","\n","print(f\"Normal data 수: {num_images_train_normal}\")\n","print(f\"COVID19 data 수: {num_images_train_covid19}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZPK-B5UEgeFA","executionInfo":{"status":"ok","timestamp":1641915130525,"user_tz":-540,"elapsed":11,"user":{"displayName":"지민진","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02076462248414665689"}},"outputId":"701bd864-be2d-47b6-ff69-5926cbb69d14"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Normal data 수: 1266\n","COVID19 data 수: 1171\n"]}]},{"cell_type":"code","source":["# 이미지 load 가볍게 해줌\n","\n","AUTOTUNE = tf.data.experimental.AUTOTUNE\n","\n","train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n","val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"],"metadata":{"id":"uNK480slge_A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 이미지 정규화\n","\n","normalization_layer = layers.experimental.preprocessing.Rescaling(1./255)\n","train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n","val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\n","test_ds = test_ds.map(lambda x, y: (normalization_layer(x), y))"],"metadata":{"id":"QHes6xR-gfyJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# CNN 모델 형성"],"metadata":{"id":"kITZjxM30y82"}},{"cell_type":"code","source":["model = Sequential()\n","model.add(Conv2D(32, (3,3), padding='same', activation='relu', input_shape=(img_height, img_width, 3))) #128x128\n","model.add(MaxPooling2D(2,2)) \n","model.add(Conv2D(64, (3,3), padding='same', activation='relu')) #64x64\n","model.add(MaxPooling2D(2,2))\n","model.add(Conv2D(128, (3,3), padding='same', activation='relu'))  #32x32\n","model.add(MaxPooling2D(2,2))\n","model.add(Conv2D(128, (3,3), padding='same', activation='relu')) #16x16\n","model.add(Flatten())\n","model.add(Dense(128, activation='relu'))\n","model.add(Dense(64, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))"],"metadata":{"id":"rtjW4bA6gga2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HnyDTeEUghgl","executionInfo":{"status":"ok","timestamp":1641915131056,"user_tz":-540,"elapsed":538,"user":{"displayName":"지민진","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02076462248414665689"}},"outputId":"c75f83a9-d705-4184-aebd-9e7fbfeb2e58"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 128, 128, 32)      896       \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 64, 64, 32)       0         \n"," )                                                               \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 64, 64, 64)        18496     \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 32, 32, 64)       0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 32, 32, 128)       73856     \n","                                                                 \n"," max_pooling2d_2 (MaxPooling  (None, 16, 16, 128)      0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 16, 16, 128)       147584    \n","                                                                 \n"," flatten (Flatten)           (None, 32768)             0         \n","                                                                 \n"," dense (Dense)               (None, 128)               4194432   \n","                                                                 \n"," dense_1 (Dense)             (None, 64)                8256      \n","                                                                 \n"," dense_2 (Dense)             (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 4,443,585\n","Trainable params: 4,443,585\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["filename = 'checkpoint-epoch-{}-batch-{}-trial-001.h5'.format(epoch, batch_size)\n","checkpoint = ModelCheckpoint(filename,             # file명을 지정합니다\n","                             monitor='val_loss',   # val_loss 값이 개선되었을때 호출됩니다\n","                             verbose=1,            # 로그를 출력합니다\n","                             save_best_only=True,  # 가장 best 값만 저장합니다\n","                             mode='auto'           # auto는 알아서 best를 찾습니다. min/max\n","                            )\n","\n","earlystopping = EarlyStopping(monitor='val_loss',  # 모니터 기준 설정 (val loss) \n","                              patience=50,         # 50회 Epoch동안 개선되지 않는다면 종료\n","                             )"],"metadata":{"id":"CnuT4eE8giXB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.compile(optimizer='adam',\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])"],"metadata":{"id":"FPDQtDoYgj9d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#모델 훈련"],"metadata":{"id":"NykyXSs901Rt"}},{"cell_type":"code","source":["model.fit(train_ds,\n","          batch_size=batch_size,\n","          validation_data=val_ds,\n","          epochs=epoch,\n","          callbacks=[checkpoint, earlystopping])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6aCQKtJVgkuE","executionInfo":{"status":"ok","timestamp":1641915542934,"user_tz":-540,"elapsed":411881,"user":{"displayName":"지민진","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02076462248414665689"}},"outputId":"de306146-ed9e-4bb8-a338-86c7069e2cf2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/500\n","16/16 [==============================] - ETA: 0s - loss: 0.4675 - accuracy: 0.7923\n","Epoch 00001: val_loss improved from inf to 0.08911, saving model to checkpoint-epoch-500-batch-128-trial-001.h5\n","16/16 [==============================] - 303s 3s/step - loss: 0.4675 - accuracy: 0.7923 - val_loss: 0.0891 - val_accuracy: 0.9651\n","Epoch 2/500\n","15/16 [===========================>..] - ETA: 0s - loss: 0.0838 - accuracy: 0.9676\n","Epoch 00002: val_loss improved from 0.08911 to 0.02841, saving model to checkpoint-epoch-500-batch-128-trial-001.h5\n","16/16 [==============================] - 1s 63ms/step - loss: 0.0849 - accuracy: 0.9677 - val_loss: 0.0284 - val_accuracy: 0.9877\n","Epoch 3/500\n","15/16 [===========================>..] - ETA: 0s - loss: 0.0487 - accuracy: 0.9854\n","Epoch 00003: val_loss did not improve from 0.02841\n","16/16 [==============================] - 1s 49ms/step - loss: 0.0482 - accuracy: 0.9856 - val_loss: 0.0305 - val_accuracy: 0.9918\n","Epoch 4/500\n","15/16 [===========================>..] - ETA: 0s - loss: 0.0459 - accuracy: 0.9846\n","Epoch 00004: val_loss improved from 0.02841 to 0.01693, saving model to checkpoint-epoch-500-batch-128-trial-001.h5\n","16/16 [==============================] - 1s 60ms/step - loss: 0.0437 - accuracy: 0.9856 - val_loss: 0.0169 - val_accuracy: 0.9938\n","Epoch 5/500\n","15/16 [===========================>..] - ETA: 0s - loss: 0.0349 - accuracy: 0.9896\n","Epoch 00005: val_loss did not improve from 0.01693\n","16/16 [==============================] - 1s 51ms/step - loss: 0.0339 - accuracy: 0.9897 - val_loss: 0.0375 - val_accuracy: 0.9877\n","Epoch 6/500\n","15/16 [===========================>..] - ETA: 0s - loss: 0.0271 - accuracy: 0.9907\n","Epoch 00006: val_loss improved from 0.01693 to 0.01187, saving model to checkpoint-epoch-500-batch-128-trial-001.h5\n","16/16 [==============================] - 1s 58ms/step - loss: 0.0282 - accuracy: 0.9897 - val_loss: 0.0119 - val_accuracy: 0.9959\n","Epoch 7/500\n","15/16 [===========================>..] - ETA: 0s - loss: 0.0251 - accuracy: 0.9929\n","Epoch 00007: val_loss did not improve from 0.01187\n","16/16 [==============================] - 1s 47ms/step - loss: 0.0245 - accuracy: 0.9928 - val_loss: 0.0193 - val_accuracy: 0.9918\n","Epoch 8/500\n","16/16 [==============================] - ETA: 0s - loss: 0.0227 - accuracy: 0.9933\n","Epoch 00008: val_loss did not improve from 0.01187\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0227 - accuracy: 0.9933 - val_loss: 0.0424 - val_accuracy: 0.9836\n","Epoch 9/500\n","15/16 [===========================>..] - ETA: 0s - loss: 0.0261 - accuracy: 0.9912\n","Epoch 00009: val_loss improved from 0.01187 to 0.00889, saving model to checkpoint-epoch-500-batch-128-trial-001.h5\n","16/16 [==============================] - 1s 58ms/step - loss: 0.0247 - accuracy: 0.9918 - val_loss: 0.0089 - val_accuracy: 0.9979\n","Epoch 10/500\n","16/16 [==============================] - ETA: 0s - loss: 0.0151 - accuracy: 0.9944\n","Epoch 00010: val_loss did not improve from 0.00889\n","16/16 [==============================] - 1s 53ms/step - loss: 0.0151 - accuracy: 0.9944 - val_loss: 0.0131 - val_accuracy: 0.9959\n","Epoch 11/500\n","15/16 [===========================>..] - ETA: 0s - loss: 0.0140 - accuracy: 0.9956\n","Epoch 00011: val_loss did not improve from 0.00889\n","16/16 [==============================] - 1s 51ms/step - loss: 0.0148 - accuracy: 0.9949 - val_loss: 0.0276 - val_accuracy: 0.9877\n","Epoch 12/500\n","15/16 [===========================>..] - ETA: 0s - loss: 0.0054 - accuracy: 0.9984\n","Epoch 00012: val_loss improved from 0.00889 to 0.00849, saving model to checkpoint-epoch-500-batch-128-trial-001.h5\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0059 - accuracy: 0.9979 - val_loss: 0.0085 - val_accuracy: 0.9979\n","Epoch 13/500\n","15/16 [===========================>..] - ETA: 0s - loss: 0.0058 - accuracy: 0.9984\n","Epoch 00013: val_loss did not improve from 0.00849\n","16/16 [==============================] - 1s 52ms/step - loss: 0.0068 - accuracy: 0.9979 - val_loss: 0.0150 - val_accuracy: 0.9938\n","Epoch 14/500\n","16/16 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 0.9979\n","Epoch 00014: val_loss improved from 0.00849 to 0.00526, saving model to checkpoint-epoch-500-batch-128-trial-001.h5\n","16/16 [==============================] - 1s 60ms/step - loss: 0.0081 - accuracy: 0.9979 - val_loss: 0.0053 - val_accuracy: 0.9979\n","Epoch 15/500\n","16/16 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 0.9990\n","Epoch 00015: val_loss did not improve from 0.00526\n","16/16 [==============================] - 1s 48ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 0.0058 - val_accuracy: 0.9979\n","Epoch 16/500\n","15/16 [===========================>..] - ETA: 0s - loss: 0.0029 - accuracy: 0.9989\n","Epoch 00016: val_loss did not improve from 0.00526\n","16/16 [==============================] - 1s 48ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.0082 - val_accuracy: 0.9979\n","Epoch 17/500\n","15/16 [===========================>..] - ETA: 0s - loss: 5.9646e-04 - accuracy: 1.0000\n","Epoch 00017: val_loss did not improve from 0.00526\n","16/16 [==============================] - 1s 50ms/step - loss: 6.5589e-04 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 0.9979\n","Epoch 18/500\n","16/16 [==============================] - ETA: 0s - loss: 5.8958e-04 - accuracy: 1.0000\n","Epoch 00018: val_loss did not improve from 0.00526\n","16/16 [==============================] - 1s 49ms/step - loss: 5.8958e-04 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 0.9979\n","Epoch 19/500\n","16/16 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 0.9990\n","Epoch 00019: val_loss did not improve from 0.00526\n","16/16 [==============================] - 1s 49ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.0484 - val_accuracy: 0.9897\n","Epoch 20/500\n","15/16 [===========================>..] - ETA: 0s - loss: 0.0084 - accuracy: 0.9984\n","Epoch 00020: val_loss improved from 0.00526 to 0.00522, saving model to checkpoint-epoch-500-batch-128-trial-001.h5\n","16/16 [==============================] - 1s 60ms/step - loss: 0.0079 - accuracy: 0.9985 - val_loss: 0.0052 - val_accuracy: 0.9959\n","Epoch 21/500\n","16/16 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9990\n","Epoch 00021: val_loss did not improve from 0.00522\n","16/16 [==============================] - 1s 47ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.0241 - val_accuracy: 0.9877\n","Epoch 22/500\n","16/16 [==============================] - ETA: 0s - loss: 9.5524e-04 - accuracy: 1.0000\n","Epoch 00022: val_loss did not improve from 0.00522\n","16/16 [==============================] - 1s 48ms/step - loss: 9.5524e-04 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 0.9959\n","Epoch 23/500\n","15/16 [===========================>..] - ETA: 0s - loss: 8.4892e-04 - accuracy: 1.0000\n","Epoch 00023: val_loss improved from 0.00522 to 0.00354, saving model to checkpoint-epoch-500-batch-128-trial-001.h5\n","16/16 [==============================] - 1s 58ms/step - loss: 7.9956e-04 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9959\n","Epoch 24/500\n","15/16 [===========================>..] - ETA: 0s - loss: 4.2900e-04 - accuracy: 1.0000\n","Epoch 00024: val_loss did not improve from 0.00354\n","16/16 [==============================] - 1s 48ms/step - loss: 4.0220e-04 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9979\n","Epoch 25/500\n","15/16 [===========================>..] - ETA: 0s - loss: 6.4854e-04 - accuracy: 1.0000\n","Epoch 00025: val_loss did not improve from 0.00354\n","16/16 [==============================] - 1s 52ms/step - loss: 6.2121e-04 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 0.9979\n","Epoch 26/500\n","15/16 [===========================>..] - ETA: 0s - loss: 1.1183e-04 - accuracy: 1.0000\n","Epoch 00026: val_loss improved from 0.00354 to 0.00154, saving model to checkpoint-epoch-500-batch-128-trial-001.h5\n","16/16 [==============================] - 1s 64ms/step - loss: 2.2973e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n","Epoch 27/500\n","15/16 [===========================>..] - ETA: 0s - loss: 1.1341e-04 - accuracy: 1.0000\n","Epoch 00027: val_loss did not improve from 0.00154\n","16/16 [==============================] - 1s 49ms/step - loss: 1.0657e-04 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 0.9979\n","Epoch 28/500\n","15/16 [===========================>..] - ETA: 0s - loss: 2.8302e-04 - accuracy: 1.0000\n","Epoch 00028: val_loss did not improve from 0.00154\n","16/16 [==============================] - 1s 49ms/step - loss: 2.6756e-04 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9959\n","Epoch 29/500\n","16/16 [==============================] - ETA: 0s - loss: 2.3078e-04 - accuracy: 1.0000\n","Epoch 00029: val_loss improved from 0.00154 to 0.00039, saving model to checkpoint-epoch-500-batch-128-trial-001.h5\n","16/16 [==============================] - 1s 60ms/step - loss: 2.3078e-04 - accuracy: 1.0000 - val_loss: 3.8999e-04 - val_accuracy: 1.0000\n","Epoch 30/500\n","15/16 [===========================>..] - ETA: 0s - loss: 3.6001e-05 - accuracy: 1.0000\n","Epoch 00030: val_loss did not improve from 0.00039\n","16/16 [==============================] - 1s 53ms/step - loss: 3.4573e-05 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n","Epoch 31/500\n","15/16 [===========================>..] - ETA: 0s - loss: 2.5074e-05 - accuracy: 1.0000\n","Epoch 00031: val_loss improved from 0.00039 to 0.00038, saving model to checkpoint-epoch-500-batch-128-trial-001.h5\n","16/16 [==============================] - 1s 67ms/step - loss: 2.4600e-05 - accuracy: 1.0000 - val_loss: 3.8296e-04 - val_accuracy: 1.0000\n","Epoch 32/500\n","16/16 [==============================] - ETA: 0s - loss: 1.2185e-05 - accuracy: 1.0000\n","Epoch 00032: val_loss improved from 0.00038 to 0.00033, saving model to checkpoint-epoch-500-batch-128-trial-001.h5\n","16/16 [==============================] - 1s 58ms/step - loss: 1.2185e-05 - accuracy: 1.0000 - val_loss: 3.3034e-04 - val_accuracy: 1.0000\n","Epoch 33/500\n","16/16 [==============================] - ETA: 0s - loss: 1.0617e-05 - accuracy: 1.0000\n","Epoch 00033: val_loss did not improve from 0.00033\n","16/16 [==============================] - 1s 50ms/step - loss: 1.0617e-05 - accuracy: 1.0000 - val_loss: 3.3106e-04 - val_accuracy: 1.0000\n","Epoch 34/500\n","16/16 [==============================] - ETA: 0s - loss: 9.2887e-06 - accuracy: 1.0000\n","Epoch 00034: val_loss did not improve from 0.00033\n","16/16 [==============================] - 1s 48ms/step - loss: 9.2887e-06 - accuracy: 1.0000 - val_loss: 3.3178e-04 - val_accuracy: 1.0000\n","Epoch 35/500\n","16/16 [==============================] - ETA: 0s - loss: 8.4007e-06 - accuracy: 1.0000\n","Epoch 00035: val_loss did not improve from 0.00033\n","16/16 [==============================] - 1s 49ms/step - loss: 8.4007e-06 - accuracy: 1.0000 - val_loss: 3.3094e-04 - val_accuracy: 1.0000\n","Epoch 36/500\n","15/16 [===========================>..] - ETA: 0s - loss: 7.5560e-06 - accuracy: 1.0000\n","Epoch 00036: val_loss improved from 0.00033 to 0.00033, saving model to checkpoint-epoch-500-batch-128-trial-001.h5\n","16/16 [==============================] - 1s 62ms/step - loss: 7.4473e-06 - accuracy: 1.0000 - val_loss: 3.3028e-04 - val_accuracy: 1.0000\n","Epoch 37/500\n","15/16 [===========================>..] - ETA: 0s - loss: 6.5816e-06 - accuracy: 1.0000\n","Epoch 00037: val_loss improved from 0.00033 to 0.00033, saving model to checkpoint-epoch-500-batch-128-trial-001.h5\n","16/16 [==============================] - 1s 65ms/step - loss: 6.8672e-06 - accuracy: 1.0000 - val_loss: 3.2997e-04 - val_accuracy: 1.0000\n","Epoch 38/500\n","15/16 [===========================>..] - ETA: 0s - loss: 6.1168e-06 - accuracy: 1.0000\n","Epoch 00038: val_loss did not improve from 0.00033\n","16/16 [==============================] - 1s 48ms/step - loss: 6.3064e-06 - accuracy: 1.0000 - val_loss: 3.3053e-04 - val_accuracy: 1.0000\n","Epoch 39/500\n","15/16 [===========================>..] - ETA: 0s - loss: 6.1619e-06 - accuracy: 1.0000\n","Epoch 00039: val_loss did not improve from 0.00033\n","16/16 [==============================] - 1s 49ms/step - loss: 5.9216e-06 - accuracy: 1.0000 - val_loss: 3.3235e-04 - val_accuracy: 1.0000\n","Epoch 40/500\n","15/16 [===========================>..] - ETA: 0s - loss: 5.6300e-06 - accuracy: 1.0000\n","Epoch 00040: val_loss did not improve from 0.00033\n","16/16 [==============================] - 1s 49ms/step - loss: 5.5491e-06 - accuracy: 1.0000 - val_loss: 3.3152e-04 - val_accuracy: 1.0000\n","Epoch 41/500\n","16/16 [==============================] - ETA: 0s - loss: 5.2341e-06 - accuracy: 1.0000\n","Epoch 00041: val_loss did not improve from 0.00033\n","16/16 [==============================] - 1s 49ms/step - loss: 5.2341e-06 - accuracy: 1.0000 - val_loss: 3.3096e-04 - val_accuracy: 1.0000\n","Epoch 42/500\n","16/16 [==============================] - ETA: 0s - loss: 4.9701e-06 - accuracy: 1.0000\n","Epoch 00042: val_loss did not improve from 0.00033\n","16/16 [==============================] - 1s 49ms/step - loss: 4.9701e-06 - accuracy: 1.0000 - val_loss: 3.3162e-04 - val_accuracy: 1.0000\n","Epoch 43/500\n","16/16 [==============================] - ETA: 0s - loss: 4.7628e-06 - accuracy: 1.0000\n","Epoch 00043: val_loss did not improve from 0.00033\n","16/16 [==============================] - 1s 48ms/step - loss: 4.7628e-06 - accuracy: 1.0000 - val_loss: 3.3181e-04 - val_accuracy: 1.0000\n","Epoch 44/500\n","15/16 [===========================>..] - ETA: 0s - loss: 4.6820e-06 - accuracy: 1.0000\n","Epoch 00044: val_loss did not improve from 0.00033\n","16/16 [==============================] - 1s 51ms/step - loss: 4.5256e-06 - accuracy: 1.0000 - val_loss: 3.3401e-04 - val_accuracy: 1.0000\n","Epoch 45/500\n","15/16 [===========================>..] - ETA: 0s - loss: 4.2664e-06 - accuracy: 1.0000\n","Epoch 00045: val_loss did not improve from 0.00033\n","16/16 [==============================] - 1s 53ms/step - loss: 4.3476e-06 - accuracy: 1.0000 - val_loss: 3.3558e-04 - val_accuracy: 1.0000\n","Epoch 46/500\n","15/16 [===========================>..] - ETA: 0s - loss: 4.4215e-06 - accuracy: 1.0000\n","Epoch 00046: val_loss did not improve from 0.00033\n","16/16 [==============================] - 1s 48ms/step - loss: 4.1716e-06 - accuracy: 1.0000 - val_loss: 3.3758e-04 - val_accuracy: 1.0000\n","Epoch 47/500\n","15/16 [===========================>..] - ETA: 0s - loss: 3.8929e-06 - accuracy: 1.0000\n","Epoch 00047: val_loss did not improve from 0.00033\n","16/16 [==============================] - 1s 48ms/step - loss: 4.0013e-06 - accuracy: 1.0000 - val_loss: 3.3837e-04 - val_accuracy: 1.0000\n","Epoch 48/500\n","15/16 [===========================>..] - ETA: 0s - loss: 3.7524e-06 - accuracy: 1.0000\n","Epoch 00048: val_loss did not improve from 0.00033\n","16/16 [==============================] - 1s 47ms/step - loss: 3.8609e-06 - accuracy: 1.0000 - val_loss: 3.3974e-04 - val_accuracy: 1.0000\n","Epoch 49/500\n","16/16 [==============================] - ETA: 0s - loss: 3.7380e-06 - accuracy: 1.0000\n","Epoch 00049: val_loss did not improve from 0.00033\n","16/16 [==============================] - 1s 49ms/step - loss: 3.7380e-06 - accuracy: 1.0000 - val_loss: 3.3786e-04 - val_accuracy: 1.0000\n","Epoch 50/500\n","15/16 [===========================>..] - ETA: 0s - loss: 3.6598e-06 - accuracy: 1.0000\n","Epoch 00050: val_loss did not improve from 0.00033\n","16/16 [==============================] - 1s 46ms/step - loss: 3.6083e-06 - accuracy: 1.0000 - val_loss: 3.4033e-04 - val_accuracy: 1.0000\n","Epoch 51/500\n","15/16 [===========================>..] - ETA: 0s - loss: 3.5944e-06 - accuracy: 1.0000\n","Epoch 00051: val_loss did not improve from 0.00033\n","16/16 [==============================] - 1s 47ms/step - loss: 3.4788e-06 - accuracy: 1.0000 - val_loss: 3.3911e-04 - val_accuracy: 1.0000\n","Epoch 52/500\n","15/16 [===========================>..] - ETA: 0s - loss: 3.4298e-06 - accuracy: 1.0000\n","Epoch 00052: val_loss did not improve from 0.00033\n","16/16 [==============================] - 1s 48ms/step - loss: 3.3848e-06 - accuracy: 1.0000 - val_loss: 3.3937e-04 - val_accuracy: 1.0000\n","Epoch 53/500\n","16/16 [==============================] - ETA: 0s - loss: 3.2556e-06 - accuracy: 1.0000\n","Epoch 00053: val_loss did not improve from 0.00033\n","16/16 [==============================] - 1s 51ms/step - loss: 3.2556e-06 - accuracy: 1.0000 - val_loss: 3.4020e-04 - val_accuracy: 1.0000\n","Epoch 54/500\n","16/16 [==============================] - ETA: 0s - loss: 3.1671e-06 - accuracy: 1.0000\n","Epoch 00054: val_loss did not improve from 0.00033\n","16/16 [==============================] - 1s 48ms/step - loss: 3.1671e-06 - accuracy: 1.0000 - val_loss: 3.3943e-04 - val_accuracy: 1.0000\n","Epoch 55/500\n","15/16 [===========================>..] - ETA: 0s - loss: 3.0258e-06 - accuracy: 1.0000\n","Epoch 00055: val_loss did not improve from 0.00033\n","16/16 [==============================] - 1s 49ms/step - loss: 3.0688e-06 - accuracy: 1.0000 - val_loss: 3.4254e-04 - val_accuracy: 1.0000\n","Epoch 56/500\n","16/16 [==============================] - ETA: 0s - loss: 2.9782e-06 - accuracy: 1.0000\n","Epoch 00056: val_loss did not improve from 0.00033\n","16/16 [==============================] - 1s 49ms/step - loss: 2.9782e-06 - accuracy: 1.0000 - val_loss: 3.3980e-04 - val_accuracy: 1.0000\n","Epoch 57/500\n","15/16 [===========================>..] - ETA: 0s - loss: 2.9198e-06 - accuracy: 1.0000\n","Epoch 00057: val_loss did not improve from 0.00033\n","16/16 [==============================] - 1s 51ms/step - loss: 2.8918e-06 - accuracy: 1.0000 - val_loss: 3.3975e-04 - val_accuracy: 1.0000\n","Epoch 58/500\n","15/16 [===========================>..] - ETA: 0s - loss: 2.7650e-06 - accuracy: 1.0000\n","Epoch 00058: val_loss did not improve from 0.00033\n","16/16 [==============================] - 1s 50ms/step - loss: 2.8187e-06 - accuracy: 1.0000 - val_loss: 3.4465e-04 - val_accuracy: 1.0000\n","Epoch 59/500\n","15/16 [===========================>..] - ETA: 0s - loss: 2.6794e-06 - accuracy: 1.0000\n","Epoch 00059: val_loss did not improve from 0.00033\n","16/16 [==============================] - 1s 46ms/step - loss: 2.7321e-06 - accuracy: 1.0000 - val_loss: 3.4496e-04 - val_accuracy: 1.0000\n","Epoch 60/500\n","15/16 [===========================>..] - ETA: 0s - loss: 2.8258e-06 - accuracy: 1.0000\n","Epoch 00060: val_loss did not improve from 0.00033\n","16/16 [==============================] - 1s 47ms/step - loss: 2.6632e-06 - accuracy: 1.0000 - val_loss: 3.4313e-04 - val_accuracy: 1.0000\n","Epoch 61/500\n","16/16 [==============================] - ETA: 0s - loss: 2.6065e-06 - accuracy: 1.0000\n","Epoch 00061: val_loss did not improve from 0.00033\n","16/16 [==============================] - 1s 49ms/step - loss: 2.6065e-06 - accuracy: 1.0000 - val_loss: 3.4539e-04 - val_accuracy: 1.0000\n","Epoch 62/500\n","15/16 [===========================>..] - ETA: 0s - loss: 2.3505e-06 - accuracy: 1.0000\n","Epoch 00062: val_loss did not improve from 0.00033\n","16/16 [==============================] - 1s 49ms/step - loss: 2.5174e-06 - accuracy: 1.0000 - val_loss: 3.4243e-04 - val_accuracy: 1.0000\n","Epoch 63/500\n","15/16 [===========================>..] - ETA: 0s - loss: 2.2938e-06 - accuracy: 1.0000\n","Epoch 00063: val_loss did not improve from 0.00033\n","16/16 [==============================] - 1s 53ms/step - loss: 2.4656e-06 - accuracy: 1.0000 - val_loss: 3.4127e-04 - val_accuracy: 1.0000\n","Epoch 64/500\n","15/16 [===========================>..] - ETA: 0s - loss: 2.3038e-06 - accuracy: 1.0000\n","Epoch 00064: val_loss did not improve from 0.00033\n","16/16 [==============================] - 1s 49ms/step - loss: 2.3993e-06 - accuracy: 1.0000 - val_loss: 3.4142e-04 - val_accuracy: 1.0000\n","Epoch 65/500\n","15/16 [===========================>..] - ETA: 0s - loss: 2.3573e-06 - accuracy: 1.0000\n","Epoch 00065: val_loss did not improve from 0.00033\n","16/16 [==============================] - 1s 49ms/step - loss: 2.3334e-06 - accuracy: 1.0000 - val_loss: 3.4365e-04 - val_accuracy: 1.0000\n","Epoch 66/500\n","15/16 [===========================>..] - ETA: 0s - loss: 2.2552e-06 - accuracy: 1.0000\n","Epoch 00066: val_loss did not improve from 0.00033\n","16/16 [==============================] - 1s 49ms/step - loss: 2.2785e-06 - accuracy: 1.0000 - val_loss: 3.4470e-04 - val_accuracy: 1.0000\n","Epoch 67/500\n","15/16 [===========================>..] - ETA: 0s - loss: 2.3274e-06 - accuracy: 1.0000\n","Epoch 00067: val_loss did not improve from 0.00033\n","16/16 [==============================] - 1s 46ms/step - loss: 2.2238e-06 - accuracy: 1.0000 - val_loss: 3.4180e-04 - val_accuracy: 1.0000\n","Epoch 68/500\n","15/16 [===========================>..] - ETA: 0s - loss: 2.2335e-06 - accuracy: 1.0000\n","Epoch 00068: val_loss did not improve from 0.00033\n","16/16 [==============================] - 1s 47ms/step - loss: 2.1675e-06 - accuracy: 1.0000 - val_loss: 3.4388e-04 - val_accuracy: 1.0000\n","Epoch 69/500\n","16/16 [==============================] - ETA: 0s - loss: 2.1229e-06 - accuracy: 1.0000\n","Epoch 00069: val_loss did not improve from 0.00033\n","16/16 [==============================] - 1s 48ms/step - loss: 2.1229e-06 - accuracy: 1.0000 - val_loss: 3.4258e-04 - val_accuracy: 1.0000\n","Epoch 70/500\n","15/16 [===========================>..] - ETA: 0s - loss: 2.0869e-06 - accuracy: 1.0000\n","Epoch 00070: val_loss did not improve from 0.00033\n","16/16 [==============================] - 1s 48ms/step - loss: 2.0712e-06 - accuracy: 1.0000 - val_loss: 3.4121e-04 - val_accuracy: 1.0000\n","Epoch 71/500\n","16/16 [==============================] - ETA: 0s - loss: 2.0159e-06 - accuracy: 1.0000\n","Epoch 00071: val_loss did not improve from 0.00033\n","16/16 [==============================] - 1s 50ms/step - loss: 2.0159e-06 - accuracy: 1.0000 - val_loss: 3.4083e-04 - val_accuracy: 1.0000\n","Epoch 72/500\n","15/16 [===========================>..] - ETA: 0s - loss: 2.0505e-06 - accuracy: 1.0000\n","Epoch 00072: val_loss did not improve from 0.00033\n","16/16 [==============================] - 1s 47ms/step - loss: 1.9720e-06 - accuracy: 1.0000 - val_loss: 3.4209e-04 - val_accuracy: 1.0000\n","Epoch 73/500\n","15/16 [===========================>..] - ETA: 0s - loss: 1.9500e-06 - accuracy: 1.0000\n","Epoch 00073: val_loss did not improve from 0.00033\n","16/16 [==============================] - 1s 53ms/step - loss: 1.9288e-06 - accuracy: 1.0000 - val_loss: 3.4407e-04 - val_accuracy: 1.0000\n","Epoch 74/500\n","16/16 [==============================] - ETA: 0s - loss: 1.8831e-06 - accuracy: 1.0000\n","Epoch 00074: val_loss did not improve from 0.00033\n","16/16 [==============================] - 1s 50ms/step - loss: 1.8831e-06 - accuracy: 1.0000 - val_loss: 3.4166e-04 - val_accuracy: 1.0000\n","Epoch 75/500\n","15/16 [===========================>..] - ETA: 0s - loss: 1.8070e-06 - accuracy: 1.0000\n","Epoch 00075: val_loss did not improve from 0.00033\n","16/16 [==============================] - 1s 49ms/step - loss: 1.8401e-06 - accuracy: 1.0000 - val_loss: 3.3972e-04 - val_accuracy: 1.0000\n","Epoch 76/500\n","15/16 [===========================>..] - ETA: 0s - loss: 1.8385e-06 - accuracy: 1.0000\n","Epoch 00076: val_loss did not improve from 0.00033\n","16/16 [==============================] - 1s 48ms/step - loss: 1.7995e-06 - accuracy: 1.0000 - val_loss: 3.3937e-04 - val_accuracy: 1.0000\n","Epoch 77/500\n","15/16 [===========================>..] - ETA: 0s - loss: 1.8684e-06 - accuracy: 1.0000\n","Epoch 00077: val_loss did not improve from 0.00033\n","16/16 [==============================] - 1s 50ms/step - loss: 1.7599e-06 - accuracy: 1.0000 - val_loss: 3.3997e-04 - val_accuracy: 1.0000\n","Epoch 78/500\n","15/16 [===========================>..] - ETA: 0s - loss: 1.7632e-06 - accuracy: 1.0000\n","Epoch 00078: val_loss did not improve from 0.00033\n","16/16 [==============================] - 1s 49ms/step - loss: 1.7252e-06 - accuracy: 1.0000 - val_loss: 3.4051e-04 - val_accuracy: 1.0000\n","Epoch 79/500\n","15/16 [===========================>..] - ETA: 0s - loss: 1.7613e-06 - accuracy: 1.0000\n","Epoch 00079: val_loss did not improve from 0.00033\n","16/16 [==============================] - 1s 49ms/step - loss: 1.6932e-06 - accuracy: 1.0000 - val_loss: 3.3821e-04 - val_accuracy: 1.0000\n","Epoch 80/500\n","16/16 [==============================] - ETA: 0s - loss: 1.6517e-06 - accuracy: 1.0000\n","Epoch 00080: val_loss did not improve from 0.00033\n","16/16 [==============================] - 1s 51ms/step - loss: 1.6517e-06 - accuracy: 1.0000 - val_loss: 3.3831e-04 - val_accuracy: 1.0000\n","Epoch 81/500\n","16/16 [==============================] - ETA: 0s - loss: 1.6151e-06 - accuracy: 1.0000\n","Epoch 00081: val_loss did not improve from 0.00033\n","16/16 [==============================] - 1s 48ms/step - loss: 1.6151e-06 - accuracy: 1.0000 - val_loss: 3.3873e-04 - val_accuracy: 1.0000\n","Epoch 82/500\n","16/16 [==============================] - ETA: 0s - loss: 1.5844e-06 - accuracy: 1.0000\n","Epoch 00082: val_loss did not improve from 0.00033\n","16/16 [==============================] - 1s 48ms/step - loss: 1.5844e-06 - accuracy: 1.0000 - val_loss: 3.4044e-04 - val_accuracy: 1.0000\n","Epoch 83/500\n","15/16 [===========================>..] - ETA: 0s - loss: 1.5453e-06 - accuracy: 1.0000\n","Epoch 00083: val_loss did not improve from 0.00033\n","16/16 [==============================] - 1s 49ms/step - loss: 1.5516e-06 - accuracy: 1.0000 - val_loss: 3.3762e-04 - val_accuracy: 1.0000\n","Epoch 84/500\n","15/16 [===========================>..] - ETA: 0s - loss: 1.4739e-06 - accuracy: 1.0000\n","Epoch 00084: val_loss did not improve from 0.00033\n","16/16 [==============================] - 1s 48ms/step - loss: 1.5202e-06 - accuracy: 1.0000 - val_loss: 3.3733e-04 - val_accuracy: 1.0000\n","Epoch 85/500\n","16/16 [==============================] - ETA: 0s - loss: 1.4906e-06 - accuracy: 1.0000\n","Epoch 00085: val_loss did not improve from 0.00033\n","16/16 [==============================] - 1s 48ms/step - loss: 1.4906e-06 - accuracy: 1.0000 - val_loss: 3.3793e-04 - val_accuracy: 1.0000\n","Epoch 86/500\n","16/16 [==============================] - ETA: 0s - loss: 1.4576e-06 - accuracy: 1.0000\n","Epoch 00086: val_loss did not improve from 0.00033\n","16/16 [==============================] - 1s 50ms/step - loss: 1.4576e-06 - accuracy: 1.0000 - val_loss: 3.3556e-04 - val_accuracy: 1.0000\n","Epoch 87/500\n","16/16 [==============================] - ETA: 0s - loss: 1.4371e-06 - accuracy: 1.0000\n","Epoch 00087: val_loss did not improve from 0.00033\n","16/16 [==============================] - 1s 50ms/step - loss: 1.4371e-06 - accuracy: 1.0000 - val_loss: 3.3297e-04 - val_accuracy: 1.0000\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f24ba39b890>"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["model.evaluate(test_ds, verbose=2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vKnrYhl4gmQk","executionInfo":{"status":"ok","timestamp":1641915628329,"user_tz":-540,"elapsed":85408,"user":{"displayName":"지민진","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02076462248414665689"}},"outputId":"12ca9250-0399-4199-976c-2ab44bdc0496"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["4/4 - 85s - loss: 0.0726 - accuracy: 0.9861 - 85s/epoch - 21s/step\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.07264123857021332, 0.986143171787262]"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["#모델 저장"],"metadata":{"id":"oAZNz7wo036x"}},{"cell_type":"code","source":["save_path = \"/content/drive/MyDrive/CodeStates/Section4/project/\"\n","file_name = 'after_GAN_epoch_1000.pkl' \n","save_path = os.path.join(save_path, file_name)\n","\n","joblib.dump(model, save_path) "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gb0QOX-fgnCi","executionInfo":{"status":"ok","timestamp":1641915686439,"user_tz":-540,"elapsed":58113,"user":{"displayName":"지민진","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02076462248414665689"}},"outputId":"5ad09858-efcc-4daf-a25c-f5b81b8aad70"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: ram://07d63b93-2c9f-456c-8ea3-9e2cf928d897/assets\n"]},{"output_type":"execute_result","data":{"text/plain":["['/content/drive/MyDrive/CodeStates/Section4/project/after_GAN_epoch_1000.pkl']"]},"metadata":{},"execution_count":15}]}]}
